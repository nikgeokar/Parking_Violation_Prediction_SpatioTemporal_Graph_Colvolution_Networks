{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:44:28.669393Z",
     "iopub.status.busy": "2021-12-26T14:44:28.668621Z",
     "iopub.status.idle": "2021-12-26T14:44:36.833339Z",
     "shell.execute_reply": "2021-12-26T14:44:36.832761Z",
     "shell.execute_reply.started": "2021-12-26T14:27:21.629074Z"
    },
    "papermill": {
     "duration": 8.187854,
     "end_time": "2021-12-26T14:44:36.833462",
     "exception": false,
     "start_time": "2021-12-26T14:44:28.645608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from six.moves import urllib\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN2\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "Project_Path='/Users/nickkarras/PycharmProjects/ParkingViolationPredictionGraph_Git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016367,
     "end_time": "2021-12-26T14:44:36.867084",
     "exception": false,
     "start_time": "2021-12-26T14:44:36.850717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1>\n",
    "<center>A3T-GCN: Attention Temporal Graph\n",
    "Convolutional Network for Parking Violataion Forecasting</center>\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths(Project_Path):\n",
    "    TestDataset=Project_Path+ '/Data/Test_Dataset_Graph.pkl'\n",
    "    TestTargets=Project_Path+ '/Data/Test_Rate_Timeseries.csv'\n",
    "    TestMask=Project_Path+ '/Data/Test_Mask.csv'\n",
    "    TrainDataset =Project_Path+ '/Data/Dataset_Graph.pkl'\n",
    "    TrainTargets=Project_Path+ '/Data/STS_Rate_Timeseries.csv'\n",
    "\n",
    "    return TestDataset,TestTargets,TestMask,TrainDataset,TrainTargets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDGES & EDGE WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_weights(Project_Path):\n",
    "    path = Project_Path+'/Data/EdgesDuration250.csv'\n",
    "    weights = 'Duration'\n",
    "    Edge_List=pd.read_csv(path,sep=',', index_col=0)\n",
    "    Distance=np.array(Edge_List[weights])\n",
    "    print(Distance.shape)\n",
    "    Edge_List=Edge_List.drop([weights], axis=1)\n",
    "    Edges=np.array(Edge_List)\n",
    "    Edges=Edges.T\n",
    "    print(Edges.shape)\n",
    "    return Edges,Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3030,)\n",
      "(2, 3030)\n"
     ]
    }
   ],
   "source": [
    "TestDataset,TestTargets,TestMask,TrainDataset,TrainTargets=paths(Project_Path)\n",
    "Edges,Distance=edge_weights(Project_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPH NO TEMPORAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5074, 222, 28, 1)\n",
      "(5074, 222, 1)\n",
      "Dataset type:   <torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x17be92460>\n",
      "Data(x=[222, 28, 1], edge_index=[2, 3030], edge_attr=[3030], y=[222, 1])\n"
     ]
    }
   ],
   "source": [
    "with open(TrainDataset, 'rb') as inp:\n",
    "    Train_Dataset = pickle.load(inp)\n",
    "Name=['Date_Sin','Holidays','Capacity','temp','humidity','Week_Day_Sin','Month_Sin','Real_Time','Γενικό Νοσοκομείο Θεσσαλονίκης «Γ. Γεννηματάς»', 'Λιμάνι' ,'Δημαρχείο Θεσσαλονίκης','Λευκός Πύργος','Αγορά Καπάνι','Λαδάδικα','Πλατεία Άθωνος','Πλατεία Αριστοτέλους','Ροτόντα','Πλατεία Αγίας Σοφίας','Πλατεία Αντιγονιδών','Μουσείο Μακεδονικού Αγώνα','Πλατεία Ναυαρίνου','Πάρκο ΧΑΝΘ','Ιερός Ναός Αγίου Δημητρίου','ΔΕΘ','ΑΠΘ','Άγαλμα Ελευθερίου Βενιζέλου','Ρωμαϊκή Αγορά Θεσσαλονίκης','Predictions']\n",
    "for i in range (0,len(Train_Dataset)):\n",
    "    Train_Dataset[i]=Train_Dataset[i].sort_values(\"Slot_id\")\n",
    "    Train_Dataset[i]=Train_Dataset[i].reset_index()\n",
    "    Train_Dataset[i]=Train_Dataset[i].drop(['index'], axis=1)\n",
    "    Train_Dataset[i]=Train_Dataset[i][Name]\n",
    "\n",
    "\n",
    "Rate_Timeseries=np.array(Train_Dataset)\n",
    "Rate_Timeseries=np.reshape(Rate_Timeseries, (len(Train_Dataset), 222,28,1))\n",
    "print(Rate_Timeseries.shape)\n",
    "\n",
    "Target=pd.read_csv(TrainTargets,sep=',', index_col=0)\n",
    "Target=np.array(Target)\n",
    "Target=Target.T\n",
    "Target=np.reshape(Target, (len(Train_Dataset), 222,1))\n",
    "print(Target.shape)\n",
    "\n",
    "graTrain=StaticGraphTemporalSignal(edge_index=Edges,edge_weight=Distance,features=Rate_Timeseries,targets=Target)\n",
    "print(\"Dataset type:  \", graTrain)\n",
    "print(next(iter(graTrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 222, 28, 1)\n",
      "(609, 222, 1)\n",
      "Dataset type:   <torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x17d9cd8b0>\n",
      "Data(x=[222, 28, 1], edge_index=[2, 3030], edge_attr=[3030], y=[222, 1])\n"
     ]
    }
   ],
   "source": [
    "with open(TestDataset, 'rb') as inp:\n",
    "    Test_Dataset = pickle.load(inp)\n",
    "Name=['Date_Sin','Holidays','Capacity','temp','humidity','Week_Day_Sin','Month_Sin','Real_Time','Γενικό Νοσοκομείο Θεσσαλονίκης «Γ. Γεννηματάς»', 'Λιμάνι' ,'Δημαρχείο Θεσσαλονίκης','Λευκός Πύργος','Αγορά Καπάνι','Λαδάδικα','Πλατεία Άθωνος','Πλατεία Αριστοτέλους','Ροτόντα','Πλατεία Αγίας Σοφίας','Πλατεία Αντιγονιδών','Μουσείο Μακεδονικού Αγώνα','Πλατεία Ναυαρίνου','Πάρκο ΧΑΝΘ','Ιερός Ναός Αγίου Δημητρίου','ΔΕΘ','ΑΠΘ','Άγαλμα Ελευθερίου Βενιζέλου','Ρωμαϊκή Αγορά Θεσσαλονίκης','Predictions']\n",
    "for i in range (0,len(Test_Dataset)):\n",
    "    Test_Dataset[i]=Test_Dataset[i].sort_values(\"Slot_id\")\n",
    "    Test_Dataset[i]=Test_Dataset[i].reset_index()\n",
    "    Test_Dataset[i]=Test_Dataset[i].drop(['index'], axis=1)\n",
    "    Test_Dataset[i]=Test_Dataset[i][Name]\n",
    "\n",
    "Rate_Timeseries=np.array(Test_Dataset)\n",
    "Rate_Timeseries=np.reshape(Rate_Timeseries, (len(Test_Dataset), 222,28,1))\n",
    "print(Rate_Timeseries.shape)\n",
    "\n",
    "Target=pd.read_csv(TestTargets,sep=',', index_col=0)\n",
    "\n",
    "Target=np.array(Target)\n",
    "Target=Target.T\n",
    "Target=np.reshape(Target, (len(Test_Dataset), 222,1))\n",
    "print(Target.shape)\n",
    "\n",
    "graTest=StaticGraphTemporalSignal(edge_index=Edges,edge_weight=Distance,features=Rate_Timeseries,targets=Target)\n",
    "print(\"Dataset type:  \", graTest)\n",
    "print(next(iter(graTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033697,
     "end_time": "2021-12-26T14:44:43.929710",
     "exception": false,
     "start_time": "2021-12-26T14:44:43.896013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train buckets:  5074\n",
      "Number of test buckets:  609\n"
     ]
    }
   ],
   "source": [
    "train_dataset=graTrain\n",
    "test_dataset=graTest\n",
    "\n",
    "print(\"Number of train buckets: \", len(set(train_dataset)))\n",
    "print(\"Number of test buckets: \", len(set(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019118,
     "end_time": "2021-12-26T14:44:45.325730",
     "exception": false,
     "start_time": "2021-12-26T14:44:45.306612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:44:45.374077Z",
     "iopub.status.busy": "2021-12-26T14:44:45.373097Z",
     "iopub.status.idle": "2021-12-26T14:45:16.840268Z",
     "shell.execute_reply": "2021-12-26T14:45:16.839682Z",
     "shell.execute_reply.started": "2021-12-26T14:27:36.727755Z"
    },
    "papermill": {
     "duration": 31.495574,
     "end_time": "2021-12-26T14:45:16.840390",
     "exception": false,
     "start_time": "2021-12-26T14:44:45.344816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_input = np.array(train_dataset.features) # (5074, 222, 24, 1)\n",
    "train_target = np.array(train_dataset.targets) # (5074, 207, 1)\n",
    "train_x_tensor = torch.from_numpy(train_input).type(torch.FloatTensor)  # (B, N, F, T)\n",
    "train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor)  # (B, N, T)\n",
    "train_dataset_new = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_new, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:45:16.886780Z",
     "iopub.status.busy": "2021-12-26T14:45:16.885865Z",
     "iopub.status.idle": "2021-12-26T14:45:17.010178Z",
     "shell.execute_reply": "2021-12-26T14:45:17.009681Z",
     "shell.execute_reply.started": "2021-12-26T14:28:07.974097Z"
    },
    "papermill": {
     "duration": 0.150197,
     "end_time": "2021-12-26T14:45:17.010312",
     "exception": false,
     "start_time": "2021-12-26T14:45:16.860115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_input = np.array(test_dataset.features) # (, 207, 2, 12)\n",
    "test_target = np.array(test_dataset.targets) # (, 207, 12)\n",
    "test_x_tensor = torch.from_numpy(test_input).type(torch.FloatTensor)# (B, N, F, T)\n",
    "test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor) # (B, N, T)\n",
    "test_dataset_new = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_new, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018593,
     "end_time": "2021-12-26T14:45:17.047998",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.029405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "Which model to choose depends on which time-series task you work on. \n",
    "\n",
    "- A3TGCN is an extension of TGCN that uses attention \n",
    "- The spatial aggregation uses GCN, the temporal aggregation a GRU\n",
    "- We can pass in periods to get an embedding for several timesteps\n",
    "- This embedding can be used to predict several steps into the future = output dimension\n",
    "- We could also do this in a loop and feed it again into the model (would be autoregressive)\n",
    "- There is only one block here. Other layers also allow stacking???\n",
    "\n",
    "<html>\n",
    "<img src=\"https://i.ibb.co/WxrJQbc/a3tgcn.png\", height=\"300\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018337,
     "end_time": "2021-12-26T14:45:17.085185",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.066848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TGCN model\n",
    "A temporal GCN (T-GCN) model was constructed by combining GCN and GRU. \n",
    "\n",
    "n historical time series traffic data were inputted into the T-GCN model to obtain n hidden states (h) that covered spatiotemporal characteristics:{h(t−n), · · · , h(t−1), h(t)}\n",
    "\n",
    "\n",
    "ut = σ(Wu ∗ (GC(A, Xt), ht−1)) \n",
    "\n",
    "rt = σ(Wr ∗ (GC(A, Xt), ht−1)) \n",
    "\n",
    "ct = tanh(Wc ∗ (GC(A, Xt), (rt ∗ ht−1)))\n",
    "\n",
    "ht = ut ∗ ht−1 + (1 − ut) ∗ ct) \n",
    "\n",
    "\n",
    "Then, the hidden states were inputted into the attention model to determine the context vector that covers the global traffic variation information. Particularly, the weight of each h was calculated by Softmax using a multilayer perception:{at−n, · · · , at−1, at}.The context vector that covers global traffic variation information is calculated by the weighted sum. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018547,
     "end_time": "2021-12-26T14:45:17.122157",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.103610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A3TGCN Model\n",
    "The A3TGCN is an extention of the TGCN model by adding an attention mechanism.\n",
    "\n",
    "The attention mechanism was introduced to re-weight the influence of historical traffic states and thus to capture the global variation trends of traffic state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:45:17.167230Z",
     "iopub.status.busy": "2021-12-26T14:45:17.166722Z",
     "iopub.status.idle": "2021-12-26T14:45:17.181682Z",
     "shell.execute_reply": "2021-12-26T14:45:17.181219Z",
     "shell.execute_reply.started": "2021-12-26T14:28:08.105670Z"
    },
    "papermill": {
     "duration": 0.041032,
     "end_time": "2021-12-26T14:45:17.181766",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.140734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalGNN(\n",
       "  (tgnn): A3TGCN2(\n",
       "    (_base_tgcn): TGCN2(\n",
       "      (conv_z): GCNConv(28, 128)\n",
       "      (linear_z): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (conv_r): GCNConv(28, 128)\n",
       "      (linear_r): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (conv_h): GCNConv(28, 128)\n",
       "      (linear_h): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (act2): ReLU()\n",
       "  (lstm): LSTM(64, 32, batch_first=True)\n",
       "  (hidden4): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (act4): ReLU()\n",
       "  (linear): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TemporalGNN(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods, batch_size):\n",
    "        super(TemporalGNN, self).__init__()\n",
    "        # Attention Temporal Graph Convolutional Cell\n",
    "        \n",
    "        self.tgnn = A3TGCN2(in_channels=node_features,  out_channels=128, periods=periods,batch_size=batch_size) # node_features=2, periods=12\n",
    "        \n",
    "        \n",
    "        self.hidden2 = Linear(128, 64)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        \n",
    "        self.lstm = nn.LSTM(64, 32, 1, batch_first=True)\n",
    "\n",
    "        \n",
    "        self.hidden4 = Linear(32, 16)\n",
    "        kaiming_uniform_(self.hidden4.weight, nonlinearity='relu')\n",
    "        self.act4 = ReLU()\n",
    "\n",
    "        self.linear = torch.nn.Linear(16, periods)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.tgnn(x, edge_index) # x [b, 222, 28, 1]  returns h [b, 222, 1]\n",
    "        h = F.relu(h) \n",
    "        \n",
    "        h0 = torch.zeros(1, h.size(0), 32).requires_grad_()\n",
    "        c0 = torch.zeros(1, h.size(0), 32).requires_grad_()\n",
    "        \n",
    "        h = self.hidden2(h)\n",
    "        h = self.act2(h)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(h, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.hidden4(out)\n",
    "        out = self.act4(out)\n",
    "\n",
    "        out = self.linear(out) \n",
    "\n",
    "        return out\n",
    "\n",
    "TemporalGNN(node_features=28, periods=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01927,
     "end_time": "2021-12-26T14:45:17.220204",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.200934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020038,
     "end_time": "2021-12-26T14:45:17.343900",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.323862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the graph once \n",
    "because it's a static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:45:17.387739Z",
     "iopub.status.busy": "2021-12-26T14:45:17.387103Z",
     "iopub.status.idle": "2021-12-26T14:45:17.390422Z",
     "shell.execute_reply": "2021-12-26T14:45:17.389947Z",
     "shell.execute_reply.started": "2021-12-25T23:05:32.742421Z"
    },
    "papermill": {
     "duration": 0.026807,
     "end_time": "2021-12-26T14:45:17.390513",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.363706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for snapshot in train_dataset:\n",
    "    static_edge_index = snapshot.edge_index\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:46:13.301157Z",
     "iopub.status.busy": "2021-12-26T14:46:13.300285Z",
     "iopub.status.idle": "2021-12-26T14:46:23.410533Z",
     "shell.execute_reply": "2021-12-26T14:46:23.411181Z",
     "shell.execute_reply.started": "2021-12-25T22:37:06.708018Z"
    },
    "papermill": {
     "duration": 10.1385,
     "end_time": "2021-12-26T14:46:23.411366",
     "exception": false,
     "start_time": "2021-12-26T14:46:13.272866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetTest_MAE_MSE(model,test_loader,metric_fn,TestMask):\n",
    "    model.eval()\n",
    "    step = 0\n",
    "    total_loss = []\n",
    "    Predictions=[]\n",
    "    true=[]\n",
    "    Test_Mask=pd.read_csv(TestMask,index_col=0)\n",
    "#     cols=[0]\n",
    "#     Test_Mask = Test_Mask.drop(Test_Mask.columns[cols],axis=1)\n",
    "    Test_Mask['New']=0\n",
    "    Test_Mask=Test_Mask.T\n",
    "    Test_Mask=Test_Mask.values.tolist()\n",
    "    P=[]\n",
    "    R=[]\n",
    "    for encoder_inputs, labels in test_loader:\n",
    "        # Get model predictions\n",
    "        y_hat = model(encoder_inputs, static_edge_index)\n",
    "        # Mean squared error\n",
    "        for ii in range (0,len(y_hat)):\n",
    "            Predictions.append(y_hat[ii])\n",
    "\n",
    "        for kk in range (0,len(labels)):\n",
    "            true.append(labels[kk])\n",
    "\n",
    "\n",
    "        loss = metric_fn(y_hat, labels)\n",
    "        total_loss.append(loss.item())\n",
    "    \n",
    "    for i in range(0,(len(Predictions))):\n",
    "        for k in range (0,len(Test_Mask[0])):\n",
    "            if Test_Mask[i][k]==1:\n",
    "                P1=Predictions[i][k]\n",
    "                P.append(float(P1))\n",
    "                R1=true[i][k]\n",
    "                R.append(float(R1))\n",
    "    MAE=tf.keras.metrics.mean_absolute_error(R, P)\n",
    "    MSE=tf.keras.metrics.mean_squared_error(R, P)\n",
    "    return MAE,MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:45:17.437982Z",
     "iopub.status.busy": "2021-12-26T14:45:17.437484Z",
     "iopub.status.idle": "2021-12-26T14:46:13.161937Z",
     "shell.execute_reply": "2021-12-26T14:46:13.161017Z",
     "shell.execute_reply.started": "2021-12-25T23:05:32.751777Z"
    },
    "papermill": {
     "duration": 55.751589,
     "end_time": "2021-12-26T14:46:13.162096",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.410507",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 69/79 [00:31<00:04,  2.18it/s]"
     ]
    }
   ],
   "source": [
    "model = TemporalGNN(node_features=28, periods=1, batch_size=batch_size)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "metric_fn=torch.nn.L1Loss()\n",
    "\n",
    "model.train()\n",
    "Test_MAE=[]\n",
    "Test_MSE=[]\n",
    "Train_Loss=[]\n",
    "for epoch in range(1,61):\n",
    "    step = 0\n",
    "    loss_list = []\n",
    "    for encoder_inputs, labels in tqdm(train_loader):\n",
    "        y_hat = model(encoder_inputs, static_edge_index)         # Get model predictions\n",
    "        loss = loss_fn(y_hat, labels) # Mean squared error #loss = torch.mean((y_hat-labels)**2)  sqrt to change it to rmse\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        step= step+ 1\n",
    "        loss_list.append(loss.item())\n",
    "    \n",
    "    Loss=sum(loss_list)/len(loss_list)\n",
    "    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, Loss))\n",
    "    MAE,MSE=GetTest_MAE_MSE(model,test_loader,metric_fn,TestMask)\n",
    "    Test_MAE.append(float(MAE))\n",
    "    Test_MSE.append(float(MSE))\n",
    "    Train_Loss.append(Loss)\n",
    "    print(\"Test MAE: {:.4f}\".format(MAE))\n",
    "    print(\"Test MSE: {:.4f}\".format(MSE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "duration": 159.672275,
   "end_time": "2021-12-26T14:46:24.067327",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-26T14:43:44.395052",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
