{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Node Edges & Edge Weights </center></h1> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import openrouteservice\n",
    "\n",
    "Project_Path='/Users/nickkarras/PycharmProjects/ParkingViolationPredictionGraph_Git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sectors=pd.read_csv(Project_Path+ '/Data/Parking_Slot_Proccesed.csv',sep=',', index_col=0)\n",
    "Nodelist=Sectors[['Slot_id','Latitude','Longitude']]\n",
    "Legal_Ilegan=pd.read_csv(Project_Path+ '/Data/Scan_Data_Reg_2.3.csv',sep=',',index_col=0)\n",
    "Unique_Sectors=Legal_Ilegan['Slot_id'].unique()\n",
    "Unique_Sectors=pd.DataFrame(Unique_Sectors, columns=['Slot_id'])\n",
    "Nodelist=pd.merge(Unique_Sectors,Nodelist, on='Slot_id')\n",
    "\n",
    "with open(Project_Path+'Data/Dataset_Graph.pkl', 'rb') as inp:\n",
    "    Train_Dataset = pickle.load(inp)\n",
    "with open(Project_Path+'Data/Test_Dataset_Graph.pkl', 'rb') as inp:\n",
    "    Test_Dataset = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated Time Arival (ETA)  using API from  \" openrouteservice \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Duration(long1,lat1,long2,lat2):\n",
    "    coords = ((long1,lat1),(long2,lat2))\n",
    "    client = openrouteservice.Client(key='test')\n",
    "    res = client.directions(coords)\n",
    "    res = client.directions(coords)\n",
    "    with(open(Project_Path+'Data/ETA.json','+w')) as f:\n",
    "        f.write(json.dumps(res,indent=4, sort_keys=True))\n",
    "\n",
    "    f = open('ETA.json')\n",
    "    data = json.load(f)\n",
    "    duration=data['routes'][0]['segments'][0]['duration']\n",
    "    f.close()\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define & Preprocess Edges / Edge Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_Edgedata(Targets):\n",
    "    Targets = (((0.9-0.1) * (Targets - np.min(Targets))) / (np.max(Targets) - np.min(Targets))) + 0.1\n",
    "    return Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Neighbors(Nodelist): \n",
    "    List=Nodelist.values.tolist()\n",
    "    x=[]\n",
    "    for i in range (0,len(List)):\n",
    "        for k in range (0,len(List)):\n",
    "             if List[i][0]!=List[k][0]:\n",
    "                ed=[]\n",
    "                ed.append(List[i])\n",
    "                ed.append(List[k])\n",
    "                x.append(ed)\n",
    "\n",
    "    Edge_W=[]\n",
    "    for i in tqdm(range (0,len(x))):\n",
    "        Distance=[]\n",
    "        b= geopy.distance.geodesic((x[i][1][1],x[i][1][2]), (x[i][0][1],x[i][0][2])).m\n",
    "        if b<250:\n",
    "\n",
    "            d=get_Duration(x[i][1][2],x[i][1][1], x[i][0][2],x[i][0][1])\n",
    "            Distance.append(x[i][0][0])\n",
    "            Distance.append(x[i][1][0])\n",
    "            Distance.append(d)\n",
    "            Edge_W.append(Distance)\n",
    "    return Edge_W\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess_Weights(Edge_W):\n",
    "    Weights=pd.DataFrame(Edge_W, columns=['Sector_1','Sector_2','Duration'])\n",
    "    Weights['Sector_2']=Weights['Sector_2'].astype(int)\n",
    "    Weights['Sector_1']=Weights['Sector_1'].astype(int)\n",
    "    Weights['Duration']=Normalize_Edgedata(a['Duration'])\n",
    "    Weights.Duration= 1-Weights.Duration\n",
    "    return Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add self-edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_Self_Edges(Weights,Nodelist):\n",
    "    Comb=[]\n",
    "    N_List=Nodelist.values.tolist()\n",
    "    for i in range (0,len(N_List)):\n",
    "        Comb.append(N_List[i][0])\n",
    "    Merged=pd.DataFrame(Comb,columns=['Sector_1'])\n",
    "    Merged['Sector_2']=Comb\n",
    "    Merged['Duration']=1\n",
    "    \n",
    "    Edgelist = pd.concat([Weights,Merged])\n",
    "    \n",
    "    Edgelist=Edgelist.reset_index()\n",
    "    Edgelist=Edgelist.drop(['index'], axis=1)\n",
    "    Edgelist['Sector_1']=Edgelist['Sector_1'].astype(int)\n",
    "    Edgelist['Sector_2']=Edgelist['Sector_2'].astype(int)\n",
    "    return Edgelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges preprocess in order to be able to fit with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Final_Edges(Edgelist,Train_Dataset,Test_Dataset):\n",
    "    Slot_idx = {name: idx for idx, name in enumerate(sorted(Train_Dataset[6][\"Slot_id\"].unique()))}\n",
    "    for i in tqdm (range(0,len(Train_Dataset))):\n",
    "        Train_Dataset[i][\"Slot_id\"] = Train_Dataset[i][\"Slot_id\"].apply(lambda name: Slot_idx[name])\n",
    "\n",
    "    for j in tqdm (range(0,len(Test_Dataset))):\n",
    "        Test_Dataset[j][\"Slot_id\"] = Test_Dataset[j][\"Slot_id\"].apply(lambda name: Slot_idx[name])\n",
    "\n",
    "    Edgelist[\"Sector_1\"] = Edgelist[\"Sector_1\"].apply(lambda name: Slot_idx[name])\n",
    "    Edgelist[\"Sector_2\"] = Edgelist[\"Sector_2\"].apply(lambda name: Slot_idx[name])\n",
    "    return Edgelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create & Save Graph Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Graph_Edges(Nodelist,Train_Dataset,Test_Dataset):\n",
    "    Edge_W=Get_Neighbors(Nodelist)\n",
    "    Weights=Preprocess_Weights(Edge_W)\n",
    "    Edgelist=Add_Self_Edges(Weights,Nodelist)\n",
    "    Edgelist=Get_Final_Edges(Edgelist,Train_Dataset,Test_Dataset)\n",
    "    return Edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Edgelist=Graph_Edges(Nodelist,Train_Dataset,Test_Dataset)\n",
    "Edgelist.to_csv(Project_Path+ '/Data/EdgesDuration250.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
