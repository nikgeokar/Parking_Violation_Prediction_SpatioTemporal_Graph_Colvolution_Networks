{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Σε αυτό το Notebook πραγματοποιείται η εκπαίδευση του μοντέλου\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Proccesing\n",
    "import pandas as pd\n",
    "#Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.layers import Input, Dense,add\n",
    "from tensorflow.keras.models import Model\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "import geopy.geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "import geopy.distance\n",
    "\n",
    "Project_Path='/Users/nickkarras/PycharmProjects/ParkingViolationPredictionGraph_Git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance_Data=pd.read_csv(Project_Path+ '/Data/Distance.csv',sep=',',index_col=0)\n",
    "Final_Weather_Data=pd.read_csv(Project_Path+ '/Data/Final_Weather_Data.csv',low_memory=False,sep=',',index_col=0)\n",
    "Legal_illegal=pd.read_csv(Project_Path+ '/Data/Scan_Data_Reg_2.3.csv',sep=',',index_col=0)\n",
    "\n",
    "Legal_illegal=Legal_illegal.loc[Legal_illegal['Key'] < '2020-01-01']\n",
    "Legal_illegal=Legal_illegal.dropna()\n",
    "Legal_illegal.to_csv(Project_Path+ '/Data/Full_TimeSeries.csv')\n",
    "\n",
    "train_data=Legal_illegal.loc[Legal_illegal['Key'] < '2019-10-01']\n",
    "test_data=Legal_illegal.loc[Legal_illegal['Key'] > '2019-10-01']\n",
    "\n",
    "train_data.to_csv(Project_Path+ '/Data/Train_TimeSeries.csv')\n",
    "test_data.to_csv(Project_Path+ '/Data/Test_TimeSeries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εδώ κάνω την παραπάνω διαδικασία εφαρμόζοντας smoothing και στο train-set και στο validation/test-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H παρακάτω συνάρτηση δέχεται  ένα σύνολο δεδομένων και επιστρέφει ένα smoothed-σύνολο δεδομένων. Ουσιαστικά χρησιμοποιώντας ένα data sample δημιουργεί τρία, δηλαδή τριπλασιάζει το σύνολο δεδομένων. Έχω περιγράψει αναλυτικά την διαδικασία στην αναφορά."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-12da5593fe19>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Help['Key'] = Help['Slot_id'].map(str)+ '+' +Help['Slot_Timeint'].map(str)\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv(Project_Path+ '/Data/Train_TimeSeries.csv',sep=',',index_col=0)\n",
    "Names=['Slot_id','Slot_Timeint','Ilegality_Rate']\n",
    "Help=train_data[Names]\n",
    "Help['Key'] = Help['Slot_id'].map(str)+ '+' +Help['Slot_Timeint'].map(str)\n",
    "ILegal_Sum = Help.groupby(['Key']).Ilegality_Rate.mean().reset_index()\n",
    "Legal_Sum=ILegal_Sum['Key'],ILegal_Sum['Ilegality_Rate']\n",
    "Help = pd.concat(Legal_Sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Return_Mean(Time_Slot,Sector,Help):\n",
    "    mean=0\n",
    "    Sector=str(Sector)\n",
    "    Time_Slot=str(Time_Slot)\n",
    "    Key=Sector+ '+' +Time_Slot\n",
    "    Help=Help.loc[Help['Key']  == Key]\n",
    "    a=Help['Ilegality_Rate'].values.tolist()\n",
    "    if Help.empty:\n",
    "        mean=0.4\n",
    "    else: \n",
    "        mean=a[0]\n",
    "        \n",
    "    if mean==0:\n",
    "        mean=0.00001\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smouth(Legal_illegal,Help):\n",
    "    #Παίρνει τα καταγεγραμμένα time-slots και τα μετατρέπει ώστε να αποτυπώνονται με το κέντρο τους \"πχ: 7:00->7:30\" \n",
    "    Time_Slots=[21600,25200,28800,32400,36000,39600,43200,46800,50400,54000,57600,61200,64800,68400,72000]\n",
    "    Time_SlotsCenter=[]\n",
    "    for i in range (0,len(Time_Slots)):\n",
    "        Time_SlotsCenter.append((Time_Slots[i]+1800)/timedelta(days=1).total_seconds())\n",
    "    Time_Slots=Time_SlotsCenter\n",
    "\n",
    "    \n",
    "    Scan_List2=Legal_illegal.values.tolist()\n",
    "    NewData=[]\n",
    "    Slots=[]\n",
    "    for i in tqdm(range(0,len(Scan_List2))):\n",
    "        Helper=[]\n",
    "        Helper2=[]\n",
    "        Rate=Scan_List2[i][6] #Πραγματικό ποστό παραβατικότητας στάθμευσης \n",
    "        Real_Time=Scan_List2[i][5] #Πραγματική ώρα του ελέγχου \n",
    "\n",
    "        #Μετράει για τον κάθε έλεγχο τις αποστάσεις απο όλα τα time slots \n",
    "        #Μετρώντας την απόσταση απο την πραγατική ώρα του ελέγχου με τα κέντρα των  timeslots\n",
    "        #Βρίσκει για τον εκάστοτε έλεγχο ποια είναι τα τρία κοντινότερα time-slots \n",
    "        Distances=[]\n",
    "        for j in range (0,len(Time_Slots)):\n",
    "            Distances.append(abs(Time_Slots[j]-Real_Time))\n",
    "        Slots=np.column_stack((Time_Slots, Distances))\n",
    "        Slots = sorted(Slots, key=lambda x: x[1])\n",
    "        Slot1,Slot2,Slot3=Slots[0][0],Slots[1][0],Slots[2][0] #3 κοντινότερα  time-slots\n",
    "        D1,D2,D3=Slots[0][1],Slots[1][1],Slots[2][1] #Χρονικές Αποστάσεις απο τα 3 κοντινότερα  time-slots\n",
    "        Sector=Scan_List2[i][0]\n",
    "       \n",
    "        #Δημιουργέι ένα data sample με όλα τα χαρακτηριστικά από το αρχικό βάζοντας σαν time slot το κοντινότερο \"Slot1\"\n",
    "        #Βάζει σαν ποσοστό παραβατικότητας το πραγματικό 'Rate'\n",
    "        #Σαν απόσταση 0, γιατί αφού βάζουμε το πραγματικό ποσοστό είναι σαν να θεωρούμε ότι βρίσκεται ακριβώς στο \n",
    "        #κέντρο του time-slot. Εξηγώ τον τύπο αναλυτικότερα στη αναφορά.\n",
    "        Mean=Return_Mean(Slot1,Sector,Help)\n",
    "        Diff=Rate/Mean\n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot1)\n",
    "        Helper.append(Rate)\n",
    "        Helper.append(0)\n",
    "        NewData.append(Helper)\n",
    "        \n",
    "        #Δημιουργέι ένα δέυτερο data sample με όλα τα χαρακτηριστικά από το αρχικό βάζοντας \n",
    "        #σαν time slot το δέυτερο  κοντινότερο\n",
    "        #Βάζει σαν ποσοστό παραβατικότητας αυτό που προκύπτει εφαρμόζοντας την γκαουσιανή\n",
    "        #Βάζει την απόσταση 'D2' απο το δέυτερο κοντινότερο timeslot\n",
    "        \n",
    "        Mean=Return_Mean(Slot2,Sector,Help)\n",
    "        Applied_Mean=Mean*Diff\n",
    "        if Applied_Mean>1:\n",
    "            Applied_Mean=1\n",
    "        \n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot2)\n",
    "        #Ο τύπος είναι \"-απόσταση σε λεπτά/210 λεπτά\"\n",
    "        #Το '0.14583' είναι το 210 λεπτά, σύμφωνα με την κανονικοποήση που έχω κάνει στην ώρα\n",
    "        X1=((-D2)/0.14583) \n",
    "        X2=np.exp(X1)\n",
    "\n",
    "        X3=(1-X2)*Applied_Mean\n",
    "        r=(Rate*X2)+X3\n",
    "    \n",
    "        Helper.append(r)\n",
    "        Helper.append(D2)\n",
    "        NewData.append(Helper)\n",
    "\n",
    "        #Δημιουργέι ένα τρίτο data sample με όλα τα χαρακτηριστικά από το αρχικό βάζοντας σαν time slot \n",
    "        #το τρίτο κοντινότερο\n",
    "        #Βάζει σαν ποσοστό παραβατικότητας αυτο που προκύπτει εφαρμόζοντας την γκαουσιανή\n",
    "        #Βάζει την απόσταση 'D3' απο το τρίτο κοντινότερο timeslot\n",
    "        \n",
    "        Mean=Return_Mean(Slot3,Sector,Help)\n",
    "        Applied_Mean=Mean*Diff\n",
    "        if Applied_Mean>1:\n",
    "            Applied_Mean=1\n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot3)\n",
    "        X1=((-D3)/0.14583)\n",
    "        X2=np.exp(X1)\n",
    "  \n",
    "        X3=(1-X2)*Applied_Mean\n",
    "        r=(Rate*X2)+X3\n",
    "        \n",
    "        Helper.append(r)\n",
    "        Helper.append(D3)\n",
    "        NewData.append(Helper)\n",
    "\n",
    "    Col=['Slot_id','Key','Date_Sin','Slot_Timeint','Covid','Time_Int','Ilegality_Rate','Holidays','Capacity','Week_Day_Sin','Month_Sin','Real_Time','Real_Rate','Time_Distance']\n",
    "    Legal_illegal = pd.DataFrame (NewData, columns = Col)\n",
    "    \n",
    "    \n",
    "    #Δημιουργεί το τελικό dataset διαγράφοντας τα χαρακτηριστικά που δέν χρειάζονται. \n",
    "    #Αλλάζει θέση σε ένα χαρακτηριστικό ώστε να είναι στην σωστή. \n",
    "    Legal_illegal=Legal_illegal.drop(['Slot_Timeint'], axis=1)\n",
    "    Legal_illegal=Legal_illegal.drop(['Time_Int'], axis=1)\n",
    "    Legal_illegal=Legal_illegal.drop(['Ilegality_Rate'], axis=1)\n",
    "    a=Legal_illegal['Time_Distance']\n",
    "    Legal_illegal=Legal_illegal.drop(['Time_Distance'], axis=1)\n",
    "    Legal_illegal.insert(8, \"Time_Distance\", a, True)\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εφόσον εφόσον χρησιμοποιήσαμε πάνω ένα sample για να δημιουργήσουμε άλλα 2 και δώσαμε τα ίδια χαρακτηριστικά έκτος του ποσοστού παραβατικότητας και του timeslot. Έχουμε δώσει και ίδο 'Key' το key είναι datetime και το χρησιμοποιώ στην συνεχεία για να κάνω merge τις ωριαίες τιμές του καιρού. Εφόσον τα 2 νέα δείγματα αντιπροσωπεύουν άλλη ώρα πρέπει να αλλάξει και το 'Key'. Στην παρακάτω συνάρτηση βρίσκουμε τα σωστά  key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Weather(Legal_illegal):\n",
    "    #Μεταρέπει την ώρα σε κανονική μορφή \n",
    "    Time=Legal_illegal['Real_Time']*timedelta(days=1).total_seconds()\n",
    "    Time=Time/3600\n",
    "    Time=Time.astype(int)\n",
    "    Time=Time.values.tolist()\n",
    "    NewT=[]\n",
    "    #Αν είναι η ώρα 9:00 την μετατρέπει σε 09:00 για να έχει την ιδια μορφή με το key του καιρού\n",
    "    for i in range (0,len(Time)):\n",
    "        Str=str(Time[i])\n",
    "        if Time[i]>=10:\n",
    "            NewT.append(Str)\n",
    "        else:\n",
    "            NewT.append('0'+Str)\n",
    "\n",
    "    #Βάζει στο τέλος της κάθε ώρας το \":00\" για να έχει την ιδια μορφή με το key του καιρού\n",
    "    Time=pd.DataFrame(NewT,columns=[\"Hour\"])\n",
    "    Time= Time[\"Hour\"].map(str)+ ':00'\n",
    "    #Παίρνει και την ημερομηνία\n",
    "    T_List=Legal_illegal.values.tolist()\n",
    "    Date=[]\n",
    "    for i in range (0,len(Legal_illegal)):\n",
    "        D,H=T_List[i][1].split(' ')\n",
    "        Date.append(D)\n",
    "\n",
    "    #Βάζει σαν νεο key την ημερομηνία\n",
    "    Legal_illegal=Legal_illegal.drop(['Key'], axis=1)\n",
    "    Legal_illegal.insert(1, \"Key\", Date, True)\n",
    "    \n",
    "    #Προσθέτει στο νέο key την ώρα\n",
    "    Key_Weather=Legal_illegal['Key'].map(str) + ' ' + Time\n",
    "    Legal_illegal=Legal_illegal.drop(['Key'], axis=1)\n",
    "    \n",
    "    #Πλεον έχω το σωστό key\n",
    "    Legal_illegal.insert(1, \"Key\", Key_Weather, True)\n",
    "    \n",
    "    #Κάνω merge με τα δεδομένα του καιρού\n",
    "    Legal_illegal=pd.merge(Legal_illegal, Final_Weather_Data, on='Key')\n",
    "    \n",
    "    #Legal_illegal=Legal_illegal.drop(['Key'], axis=1)\n",
    "    #print(Legal_illegal.columns)\n",
    "    return Legal_illegal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMeans(Scans_Data2):\n",
    "    Scans_Data2['Key1'] = Scans_Data2['Slot_id'].map(str)+ '+' +Scans_Data2['Key'].map(str)+ '+' +Scans_Data2['Date_Sin'].map(str) + '+' + Scans_Data2['Covid'].map(str)+ '+' + Scans_Data2['Holidays'].map(str)+ '+'+Scans_Data2['Capacity'].map(str)+ '+'+Scans_Data2['Week_Day_Sin'].map(str)+ '+'+Scans_Data2['Month_Sin'].map(str)+ '+'+Scans_Data2['Real_Time'].map(str)+ '+'+Scans_Data2['temp'].map(str)+ '+'+Scans_Data2['humidity'].map(str)\n",
    "    Scans_Data2=Scans_Data2['Key1'],Scans_Data2['Time_Distance'],Scans_Data2['Real_Rate']\n",
    "    Headers=['Key1','Time_Distance','Real_Rate']\n",
    "    Scans_Data2 = pd.concat(Scans_Data2, axis=1, keys=Headers)\n",
    "    \n",
    "    Time_Int = Scans_Data2.groupby([\"Key1\"]).Time_Distance.mean().reset_index()\n",
    "    ILegal_Sum = Scans_Data2.groupby([\"Key1\"]).Real_Rate.mean().reset_index()\n",
    "    Legal_Sum=ILegal_Sum['Key1'],Time_Int['Time_Distance'],ILegal_Sum['Real_Rate']\n",
    "    Headers=['Key1','Time_Distance','Real_Rate']\n",
    "    Legal_illegal = pd.concat(Legal_Sum, axis=1, keys=Headers)\n",
    "    \n",
    "    \n",
    "    Scan_List2=Legal_illegal.values.tolist()\n",
    "    Slot_id=[]\n",
    "    Key=[]\n",
    "    Date_Sin=[]\n",
    "    Covid=[]\n",
    "    Holidays=[]\n",
    "    Capacity=[]\n",
    "    Week_Day_Sin=[]\n",
    "    Month_Sin=[]\n",
    "    Real_Time=[]\n",
    "    temp=[]\n",
    "    humidity=[]\n",
    "    \n",
    "    for i in tqdm(range(0,len(Scan_List2))):\n",
    "        Slot_id_V,Key_V,Date_Sin_V,Covid_V,Holidays_V,Capacity_V,Week_Day_Sin_V,Month_Sin_V,Real_Time_V,temp_V,humidity_V=Scan_List2[i][0].split('+')\n",
    "        Slot_id.append(Slot_id_V)\n",
    "        Key.append(Key_V)\n",
    "        Date_Sin.append(Date_Sin_V)\n",
    "        Covid.append(Covid_V)\n",
    "        Holidays.append(Holidays_V)\n",
    "        Capacity.append(Capacity_V)\n",
    "        Week_Day_Sin.append(Week_Day_Sin_V)\n",
    "        Month_Sin.append(Month_Sin_V)\n",
    "        Real_Time.append(Real_Time_V)\n",
    "        temp.append(temp_V)\n",
    "        humidity.append(humidity_V)\n",
    "    Legal_illegal.insert(1, \"Slot_id\", Slot_id, True)\n",
    "    Legal_illegal.insert(2, \"Key\", Key, True)\n",
    "    Legal_illegal.insert(3, \"Date_Sin\", Date_Sin, True)\n",
    "    Legal_illegal.insert(4, \"Covid\",  Covid, True)\n",
    "    Legal_illegal.insert(5, \"Holidays\", Holidays, True)\n",
    "    Legal_illegal.insert(6, \"Capacity\", Capacity, True)\n",
    "    Legal_illegal.insert(7, \"Week_Day_Sin\", Week_Day_Sin, True)\n",
    "    Legal_illegal.insert(8, \"Month_Sin\", Month_Sin, True)\n",
    "    Legal_illegal.insert(9, \"Real_Time\", Real_Time, True)\n",
    "    Legal_illegal.insert(10, \"temp\", temp, True)\n",
    "    Legal_illegal.insert(11, \"humidity\", humidity, True)\n",
    "    Legal_illegal=Legal_illegal.drop(['Key1'], axis=1)\n",
    "    \n",
    "    Columns2=['Slot_id','Key', 'Date_Sin', 'Covid', 'Holidays', 'Capacity', 'Week_Day_Sin',\n",
    "    'Month_Sin', 'Time_Distance', 'Real_Time', 'Real_Rate', 'temp','humidity']\n",
    "    Legal_illegal=Legal_illegal[Columns2]\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η παρακάτω συνάρτηση κάνει merge με το αρχείο από τις αποστάσεις των τομέων από τα 19 σημεία ενδιαφέροντος και διαγράφει το slot id γιατί δεν το χρησιμοποιούμε στην εκπαίδευση "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Slot_Distances(Legal_illegal):\n",
    "    Legal_illegal['Slot_id'] = Legal_illegal['Slot_id'].astype(float)\n",
    "    Legal_illegal['Slot_id'] = Legal_illegal['Slot_id'].astype(int)\n",
    "    Legal_illegal=pd.merge(Legal_illegal, Distance_Data, on='Slot_id')\n",
    "    #Legal_illegal=Legal_illegal.drop(['Slot_id'], axis=1)\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η παρακάτω συνάρτηση ουσιαστικά ενώνει τις τρεις παραπάνω συναρτήσεις και αυτές αποτελούν την διαδικασία του smoothing. Όπου έχοντας σαν είσοδο το data-set που δημιούργησα στο προηγούμενο notebook παίρνω στην έξοδο το smoothed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_Smoothing(Legal_illegal,Help):\n",
    "    Legal_illegal=Smouth(Legal_illegal,Help)\n",
    "    Legal_illegal=Get_Weather(Legal_illegal)\n",
    "    Legal_illegal=GetMeans(Legal_illegal)\n",
    "    Legal_illegal=Get_Slot_Distances(Legal_illegal)\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Test(Test): \n",
    "    #Σαν απόσταση βάζει 0, γιατί αφού έχουμε το πραγματικό ποσοστό είναι σαν να θεωρούμε ότι βρίσκεται ακριβώς στο \n",
    "    #κέντρο του time-slot. Εξηγώ τον τύπο αναλυτικότερα στη αναφορά.\n",
    "    Test['Time_Distance']=0\n",
    "    Test=Test.drop(['Time_Int'], axis=1)\n",
    "    a=Test['Slot_Timeint']\n",
    "    b=Test['Ilegality_Rate']\n",
    "    Test=Test.drop(['Slot_Timeint'], axis=1)\n",
    "    Test=Test.drop(['Ilegality_Rate'], axis=1)\n",
    "    Test.insert(9, \"Real_Time\", a, True)\n",
    "    Test.insert(10, \"Real_Rate\", b, True)\n",
    "    \n",
    "    Test=pd.merge(Test, Final_Weather_Data, on='Key')\n",
    "    #Test=Test.drop(['Key'], axis=1)\n",
    "    \n",
    "    Test=pd.merge(Test, Distance_Data, on='Slot_id')\n",
    "    #Test=Test.drop(['Slot_id'], axis=1)\n",
    "    return Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88870/88870 [00:43<00:00, 2029.44it/s]\n",
      "100%|██████████| 236187/236187 [00:00<00:00, 1252509.82it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv(Project_Path+ '/Data/Train_TimeSeries.csv',sep=',',index_col=0)\n",
    "test_data=pd.read_csv(Project_Path+ '/Data/Test_TimeSeries.csv',sep=',',index_col=0)\n",
    "\n",
    "TestDF=Prepare_Test(test_data) #No smoothing\n",
    "TrainDF=Apply_Smoothing(train_data,Help) #Smoothing\n",
    "\n",
    "TrainDF=TrainDF.drop(['Time_Distance'], axis=1)\n",
    "TestDF=TestDF.drop(['Time_Distance'], axis=1)\n",
    "\n",
    "TrainDF.to_csv(Project_Path+ '/Data/Ts_Train_TimeSeries.csv')\n",
    "TestDF.to_csv(Project_Path+ '/Data/Ts_Test_TimeSeries.csv')\n",
    "\n",
    "TrainDF=TrainDF.drop(['Slot_id'], axis=1)\n",
    "TrainDF=TrainDF.drop(['Key'], axis=1)\n",
    "TestDF=TestDF.drop(['Slot_id'], axis=1)\n",
    "TestDF=TestDF.drop(['Key'], axis=1)\n",
    "train_data=TrainDF.drop(['Real_Rate'], axis=1)\n",
    "test_data=TestDF.drop(['Real_Rate'], axis=1)\n",
    "\n",
    "Standar_Scaller = StandardScaler()\n",
    "train_data=Standar_Scaller.fit_transform(train_data)\n",
    "with open(Project_Path + '/Standar_Scaller.pkl', 'wb') as f:\n",
    "    pickle.dump(Standar_Scaller, f,  protocol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
