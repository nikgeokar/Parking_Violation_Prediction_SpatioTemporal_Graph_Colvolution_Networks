{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Spatial Smoothing Process</center></h1> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "Project_Path='Project/Path'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance_Data=pd.read_csv(Project_Path+ '/Data/Distance.csv',sep=',',index_col=0)\n",
    "Final_Weather_Data=pd.read_csv(Project_Path+ '/Data/Final_Weather_Data.csv',low_memory=False,sep=',',index_col=0)\n",
    "Legal_illegal=pd.read_csv(Project_Path+ '/Data/Scan_Data_Reg_2.3.csv',sep=',',index_col=0)\n",
    "train_data=pd.read_csv(Project_Path+ '/Data/Train_TimeSeries.csv',sep=',',index_col=0)\n",
    "test_data=pd.read_csv(Project_Path+ '/Data/Test_TimeSeries.csv',sep=',',index_col=0)\n",
    "Names=['Slot_id','Slot_Timeint','Ilegality_Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following procedure apply the spatial smoothing process. Essentially using one data sample creates three, that is, it triples the data set. We have described the process in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculation of the mean parking violation rate for the given sector and timeslot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Return_Mean(Time_Slot,Sector,train_data,Names):\n",
    "    Help=train_data[Names]\n",
    "    ILegal_Sum = Help.groupby(['Slot_id','Slot_Timeint']).Ilegality_Rate.mean().reset_index()\n",
    "    ILegal_Sum=ILegal_Sum.loc[(ILegal_Sum['Slot_id']  == str(Sector)) & (ILegal_Sum['Slot_Timeint'] ==str(Time_Slot))]\n",
    "    a=ILegal_Sum['Ilegality_Rate'].values.tolist()\n",
    "    if ILegal_Sum.empty:\n",
    "        mean=0.4\n",
    "    else: \n",
    "        mean=a[0]\n",
    "        \n",
    "    if mean==0:\n",
    "        mean=0.00001\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part of spatial smoothing method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smouth(Legal_illegal,Names):\n",
    "    Time_Slots=[21600,25200,28800,32400,36000,39600,43200,46800,50400,54000,57600,61200,64800,68400,72000]\n",
    "    Time_SlotsCenter=[]\n",
    "    for i in range (0,len(Time_Slots)):\n",
    "        Time_SlotsCenter.append((Time_Slots[i]+1800)/timedelta(days=1).total_seconds())\n",
    "    Time_Slots=Time_SlotsCenter\n",
    "\n",
    "    Scan_List2=Legal_illegal.values.tolist()\n",
    "    NewData=[]\n",
    "    Slots=[]\n",
    "    for i in tqdm(range(0,len(Scan_List2))):\n",
    "        Helper=[]\n",
    "        Helper2=[]\n",
    "        Rate=Scan_List2[i][6]  \n",
    "        Real_Time=Scan_List2[i][5]\n",
    "\n",
    "\n",
    "        Distances=[]\n",
    "        for j in range (0,len(Time_Slots)):\n",
    "            Distances.append(abs(Time_Slots[j]-Real_Time))\n",
    "        Slots=np.column_stack((Time_Slots, Distances))\n",
    "        Slots = sorted(Slots, key=lambda x: x[1])\n",
    "        Slot1,Slot2,Slot3=Slots[0][0],Slots[1][0],Slots[2][0] \n",
    "        D1,D2,D3=Slots[0][1],Slots[1][1],Slots[2][1] \n",
    "        Sector=Scan_List2[i][0]    \n",
    "        \n",
    "        Mean=Return_Mean(Slot1,Sector,Legal_illegal,Names)\n",
    "        Diff=Rate/Mean\n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot1)\n",
    "        Helper.append(Rate)\n",
    "        Helper.append(0)\n",
    "        NewData.append(Helper)       \n",
    "        \n",
    "        Mean=Return_Mean(Slot2,Sector,Legal_illegal,Names)\n",
    "        Applied_Mean=Mean*Diff\n",
    "        if Applied_Mean>1:\n",
    "            Applied_Mean=1 \n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot2)\n",
    "\n",
    "        X1=((-D2)/0.14583) \n",
    "        X2=np.exp(X1)\n",
    "\n",
    "        X3=(1-X2)*Applied_Mean\n",
    "        r=(Rate*X2)+X3\n",
    "    \n",
    "        Helper.append(r)\n",
    "        Helper.append(D2)\n",
    "        NewData.append(Helper)\n",
    "        \n",
    "        Mean=Return_Mean(Slot3,Sector,Legal_illegal,Names)\n",
    "        Applied_Mean=Mean*Diff\n",
    "        if Applied_Mean>1:\n",
    "            Applied_Mean=1\n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot3)\n",
    "        X1=((-D3)/0.14583)\n",
    "        X2=np.exp(X1)\n",
    "  \n",
    "        X3=(1-X2)*Applied_Mean\n",
    "        r=(Rate*X2)+X3\n",
    "        \n",
    "        Helper.append(r)\n",
    "        Helper.append(D3)\n",
    "        NewData.append(Helper)\n",
    "\n",
    "    Col=['Slot_id','Key','Date_Sin','Slot_Timeint','Covid','Time_Int','Ilegality_Rate','Holidays','Capacity','Week_Day_Sin','Month_Sin','Real_Time','Real_Rate','Time_Distance']\n",
    "    Legal_illegal = pd.DataFrame (NewData, columns = Col)\n",
    "    \n",
    "    Legal_illegal=Legal_illegal.drop(['Slot_Timeint'], axis=1)\n",
    "    Legal_illegal=Legal_illegal.drop(['Time_Int'], axis=1)\n",
    "    Legal_illegal=Legal_illegal.drop(['Ilegality_Rate'], axis=1)\n",
    "    a=Legal_illegal['Time_Distance']\n",
    "    Legal_illegal=Legal_illegal.drop(['Time_Distance'], axis=1)\n",
    "    Legal_illegal.insert(8, \"Time_Distance\", a, True)\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get weather info for the new data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Weather(Legal_illegal):\n",
    "    Time=Legal_illegal['Real_Time']*timedelta(days=1).total_seconds()\n",
    "    Time=Time/3600\n",
    "    Time=Time.astype(int)\n",
    "    Time=Time.values.tolist()\n",
    "    NewT=[]\n",
    "    \n",
    "    for i in range (0,len(Time)):\n",
    "        Str=str(Time[i])\n",
    "        if Time[i]>=10:\n",
    "            NewT.append(Str)\n",
    "        else:\n",
    "            NewT.append('0'+Str)\n",
    "\n",
    "    Time=pd.DataFrame(NewT,columns=[\"Hour\"])\n",
    "    Time= Time[\"Hour\"].map(str)+ ':00'\n",
    "\n",
    "    T_List=Legal_illegal.values.tolist()\n",
    "    Date=[]\n",
    "    for i in range (0,len(Legal_illegal)):\n",
    "        D,H=T_List[i][1].split(' ')\n",
    "        Date.append(D)\n",
    "\n",
    "    Legal_illegal=Legal_illegal.drop(['Key'], axis=1)\n",
    "    Legal_illegal.insert(1, \"Key\", Date, True)   \n",
    "    Key_Weather=Legal_illegal['Key'].map(str) + ' ' + Time\n",
    "    Legal_illegal=Legal_illegal.drop(['Key'], axis=1)  \n",
    "    Legal_illegal.insert(1, \"Key\", Key_Weather, True)   \n",
    "    Legal_illegal=pd.merge(Legal_illegal, Final_Weather_Data, on='Key')   \n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplication using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMeans(Scans_Data2):\n",
    "    Scans_Data2['Key1'] = Scans_Data2['Slot_id'].map(str)+ '+' +Scans_Data2['Key'].map(str)+ '+' +Scans_Data2['Date_Sin'].map(str) + '+' + Scans_Data2['Covid'].map(str)+ '+' + Scans_Data2['Holidays'].map(str)+ '+'+Scans_Data2['Capacity'].map(str)+ '+'+Scans_Data2['Week_Day_Sin'].map(str)+ '+'+Scans_Data2['Month_Sin'].map(str)+ '+'+Scans_Data2['Real_Time'].map(str)+ '+'+Scans_Data2['temp'].map(str)+ '+'+Scans_Data2['humidity'].map(str)\n",
    "    Scans_Data2=Scans_Data2['Key1'],Scans_Data2['Time_Distance'],Scans_Data2['Real_Rate']\n",
    "    Headers=['Key1','Time_Distance','Real_Rate']\n",
    "    Scans_Data2 = pd.concat(Scans_Data2, axis=1, keys=Headers)\n",
    "    \n",
    "    Time_Int = Scans_Data2.groupby([\"Key1\"]).Time_Distance.mean().reset_index()\n",
    "    ILegal_Sum = Scans_Data2.groupby([\"Key1\"]).Real_Rate.mean().reset_index()\n",
    "    Legal_Sum=ILegal_Sum['Key1'],Time_Int['Time_Distance'],ILegal_Sum['Real_Rate']\n",
    "    Headers=['Key1','Time_Distance','Real_Rate']\n",
    "    Legal_illegal = pd.concat(Legal_Sum, axis=1, keys=Headers)\n",
    "    \n",
    "    \n",
    "    Scan_List2=Legal_illegal.values.tolist()\n",
    "    Slot_id=[]\n",
    "    Key=[]\n",
    "    Date_Sin=[]\n",
    "    Covid=[]\n",
    "    Holidays=[]\n",
    "    Capacity=[]\n",
    "    Week_Day_Sin=[]\n",
    "    Month_Sin=[]\n",
    "    Real_Time=[]\n",
    "    temp=[]\n",
    "    humidity=[]\n",
    "    \n",
    "    for i in tqdm(range(0,len(Scan_List2))):\n",
    "        Slot_id_V,Key_V,Date_Sin_V,Covid_V,Holidays_V,Capacity_V,Week_Day_Sin_V,Month_Sin_V,Real_Time_V,temp_V,humidity_V=Scan_List2[i][0].split('+')\n",
    "        Slot_id.append(Slot_id_V)\n",
    "        Key.append(Key_V)\n",
    "        Date_Sin.append(Date_Sin_V)\n",
    "        Covid.append(Covid_V)\n",
    "        Holidays.append(Holidays_V)\n",
    "        Capacity.append(Capacity_V)\n",
    "        Week_Day_Sin.append(Week_Day_Sin_V)\n",
    "        Month_Sin.append(Month_Sin_V)\n",
    "        Real_Time.append(Real_Time_V)\n",
    "        temp.append(temp_V)\n",
    "        humidity.append(humidity_V)\n",
    "    Legal_illegal.insert(1, \"Slot_id\", Slot_id, True)\n",
    "    Legal_illegal.insert(2, \"Key\", Key, True)\n",
    "    Legal_illegal.insert(3, \"Date_Sin\", Date_Sin, True)\n",
    "    Legal_illegal.insert(4, \"Covid\",  Covid, True)\n",
    "    Legal_illegal.insert(5, \"Holidays\", Holidays, True)\n",
    "    Legal_illegal.insert(6, \"Capacity\", Capacity, True)\n",
    "    Legal_illegal.insert(7, \"Week_Day_Sin\", Week_Day_Sin, True)\n",
    "    Legal_illegal.insert(8, \"Month_Sin\", Month_Sin, True)\n",
    "    Legal_illegal.insert(9, \"Real_Time\", Real_Time, True)\n",
    "    Legal_illegal.insert(10, \"temp\", temp, True)\n",
    "    Legal_illegal.insert(11, \"humidity\", humidity, True)\n",
    "    Legal_illegal=Legal_illegal.drop(['Key1'], axis=1)\n",
    "    \n",
    "    Columns2=['Slot_id','Key', 'Date_Sin', 'Covid', 'Holidays', 'Capacity', 'Week_Day_Sin',\n",
    "    'Month_Sin', 'Time_Distance', 'Real_Time', 'Real_Rate', 'temp','humidity']\n",
    "    Legal_illegal=Legal_illegal[Columns2]\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing sector value with Poi distance based vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Slot_Distances(Legal_illegal):\n",
    "    Legal_illegal['Slot_id'] = Legal_illegal['Slot_id'].astype(float)\n",
    "    Legal_illegal['Slot_id'] = Legal_illegal['Slot_id'].astype(int)\n",
    "    Legal_illegal=pd.merge(Legal_illegal, Distance_Data, on='Slot_id')\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Train / Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_Smoothing(Legal_illegal,Names):\n",
    "    Legal_illegal=Smouth(Legal_illegal,Names)\n",
    "    Legal_illegal=Get_Weather(Legal_illegal)\n",
    "    Legal_illegal=GetMeans(Legal_illegal)\n",
    "    Legal_illegal=Get_Slot_Distances(Legal_illegal)\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Test(Test): \n",
    "    Test['Time_Distance']=0\n",
    "    Test=Test.drop(['Time_Int'], axis=1)\n",
    "    a=Test['Slot_Timeint']\n",
    "    b=Test['Ilegality_Rate']\n",
    "    Test=Test.drop(['Slot_Timeint'], axis=1)\n",
    "    Test=Test.drop(['Ilegality_Rate'], axis=1)\n",
    "    Test.insert(9, \"Real_Time\", a, True)\n",
    "    Test.insert(10, \"Real_Rate\", b, True)\n",
    "    Test=pd.merge(Test, Final_Weather_Data, on='Key')\n",
    "    Test=pd.merge(Test, Distance_Data, on='Slot_id')\n",
    "    return Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestDF=Prepare_Test(test_data) #No smoothing\n",
    "TrainDF=Apply_Smoothing(train_data,Names) #Smoothing\n",
    "TrainDF=TrainDF.drop(['Time_Distance'], axis=1)\n",
    "TestDF=TestDF.drop(['Time_Distance'], axis=1)\n",
    "TrainDF.to_csv(Project_Path+ '/Data/Ts_Train_TimeSeries.csv')\n",
    "TestDF.to_csv(Project_Path+ '/Data/Ts_Test_TimeSeries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Standar Scaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDF=TrainDF.drop(['Slot_id'], axis=1)\n",
    "TrainDF=TrainDF.drop(['Key'], axis=1)\n",
    "TestDF=TestDF.drop(['Slot_id'], axis=1)\n",
    "TestDF=TestDF.drop(['Key'], axis=1)\n",
    "train_data=TrainDF.drop(['Real_Rate'], axis=1)\n",
    "test_data=TestDF.drop(['Real_Rate'], axis=1)\n",
    "\n",
    "Standar_Scaller = StandardScaler()\n",
    "train_data=Standar_Scaller.fit_transform(train_data)\n",
    "with open(Project_Path + '/Standar_Scaller.pkl', 'wb') as f:\n",
    "    pickle.dump(Standar_Scaller, f,  protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
