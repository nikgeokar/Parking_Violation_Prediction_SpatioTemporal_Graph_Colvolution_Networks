{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Σε αυτό το Notebook πραγματοποιείται η εκπαίδευση του μοντέλου\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.layers import Input, Dense,add\n",
    "from tensorflow.keras.models import Model\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "import geopy.geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "import geopy.distance\n",
    "\n",
    "Project_Path='/Users/nickkarras/PycharmProjects/ParkingViolationPredictionGraph_Git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance_Data=pd.read_csv(Project_Path+ '/Data/Distance.csv',sep=',',index_col=0)\n",
    "Final_Weather_Data=pd.read_csv(Project_Path+ '/Data/Final_Weather_Data.csv',low_memory=False,sep=',',index_col=0)\n",
    "Legal_illegal=pd.read_csv(Project_Path+ '/Data/Scan_Data_Reg_2.3.csv',sep=',',index_col=0)\n",
    "train_data=pd.read_csv(Project_Path+ '/Data/Train_TimeSeries.csv',sep=',',index_col=0)\n",
    "test_data=pd.read_csv(Project_Path+ '/Data/Test_TimeSeries.csv',sep=',',index_col=0)\n",
    "Names=['Slot_id','Slot_Timeint','Ilegality_Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εδώ κάνω την παραπάνω διαδικασία εφαρμόζοντας smoothing και στο train-set και στο validation/test-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H παρακάτω συνάρτηση δέχεται  ένα σύνολο δεδομένων και επιστρέφει ένα smoothed-σύνολο δεδομένων. Ουσιαστικά χρησιμοποιώντας ένα data sample δημιουργεί τρία, δηλαδή τριπλασιάζει το σύνολο δεδομένων. Έχω περιγράψει αναλυτικά την διαδικασία στην αναφορά."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Return_Mean(Time_Slot,Sector,train_data,Names):\n",
    "    Help=train_data[Names]\n",
    "    ILegal_Sum = Help.groupby(['Slot_id','Slot_Timeint']).Ilegality_Rate.mean().reset_index()\n",
    "    ILegal_Sum=ILegal_Sum.loc[(ILegal_Sum['Slot_id']  == str(Sector)) & (ILegal_Sum['Slot_Timeint'] ==str(Time_Slot))]\n",
    "    a=ILegal_Sum['Ilegality_Rate'].values.tolist()\n",
    "    if ILegal_Sum.empty:\n",
    "        mean=0.4\n",
    "    else: \n",
    "        mean=a[0]\n",
    "        \n",
    "    if mean==0:\n",
    "        mean=0.00001\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smouth(Legal_illegal,Names):\n",
    "    #Παίρνει τα καταγεγραμμένα time-slots και τα μετατρέπει ώστε να αποτυπώνονται με το κέντρο τους \"πχ: 7:00->7:30\" \n",
    "    Time_Slots=[21600,25200,28800,32400,36000,39600,43200,46800,50400,54000,57600,61200,64800,68400,72000]\n",
    "    Time_SlotsCenter=[]\n",
    "    for i in range (0,len(Time_Slots)):\n",
    "        Time_SlotsCenter.append((Time_Slots[i]+1800)/timedelta(days=1).total_seconds())\n",
    "    Time_Slots=Time_SlotsCenter\n",
    "\n",
    "    \n",
    "    Scan_List2=Legal_illegal.values.tolist()\n",
    "    NewData=[]\n",
    "    Slots=[]\n",
    "    for i in tqdm(range(0,len(Scan_List2))):\n",
    "        Helper=[]\n",
    "        Helper2=[]\n",
    "        Rate=Scan_List2[i][6] #Πραγματικό ποστό παραβατικότητας στάθμευσης \n",
    "        Real_Time=Scan_List2[i][5] #Πραγματική ώρα του ελέγχου \n",
    "\n",
    "        #Μετράει για τον κάθε έλεγχο τις αποστάσεις απο όλα τα time slots \n",
    "        #Μετρώντας την απόσταση απο την πραγατική ώρα του ελέγχου με τα κέντρα των  timeslots\n",
    "        #Βρίσκει για τον εκάστοτε έλεγχο ποια είναι τα τρία κοντινότερα time-slots \n",
    "        Distances=[]\n",
    "        for j in range (0,len(Time_Slots)):\n",
    "            Distances.append(abs(Time_Slots[j]-Real_Time))\n",
    "        Slots=np.column_stack((Time_Slots, Distances))\n",
    "        Slots = sorted(Slots, key=lambda x: x[1])\n",
    "        Slot1,Slot2,Slot3=Slots[0][0],Slots[1][0],Slots[2][0] #3 κοντινότερα  time-slots\n",
    "        D1,D2,D3=Slots[0][1],Slots[1][1],Slots[2][1] #Χρονικές Αποστάσεις απο τα 3 κοντινότερα  time-slots\n",
    "        Sector=Scan_List2[i][0]\n",
    "       \n",
    "        #Δημιουργέι ένα data sample με όλα τα χαρακτηριστικά από το αρχικό βάζοντας σαν time slot το κοντινότερο \"Slot1\"\n",
    "        #Βάζει σαν ποσοστό παραβατικότητας το πραγματικό 'Rate'\n",
    "        #Σαν απόσταση 0, γιατί αφού βάζουμε το πραγματικό ποσοστό είναι σαν να θεωρούμε ότι βρίσκεται ακριβώς στο \n",
    "        #κέντρο του time-slot. Εξηγώ τον τύπο αναλυτικότερα στη αναφορά.\n",
    "        Mean=Return_Mean(Slot1,Sector,Legal_illegal,Names)\n",
    "        Diff=Rate/Mean\n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot1)\n",
    "        Helper.append(Rate)\n",
    "        Helper.append(0)\n",
    "        NewData.append(Helper)\n",
    "        \n",
    "        #Δημιουργέι ένα δέυτερο data sample με όλα τα χαρακτηριστικά από το αρχικό βάζοντας \n",
    "        #σαν time slot το δέυτερο  κοντινότερο\n",
    "        #Βάζει σαν ποσοστό παραβατικότητας αυτό που προκύπτει εφαρμόζοντας την γκαουσιανή\n",
    "        #Βάζει την απόσταση 'D2' απο το δέυτερο κοντινότερο timeslot\n",
    "        \n",
    "        Mean=Return_Mean(Slot2,Sector,Legal_illegal,Names)\n",
    "        Applied_Mean=Mean*Diff\n",
    "        if Applied_Mean>1:\n",
    "            Applied_Mean=1\n",
    "        \n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot2)\n",
    "        #Ο τύπος είναι \"-απόσταση σε λεπτά/210 λεπτά\"\n",
    "        #Το '0.14583' είναι το 210 λεπτά, σύμφωνα με την κανονικοποήση που έχω κάνει στην ώρα\n",
    "        X1=((-D2)/0.14583) \n",
    "        X2=np.exp(X1)\n",
    "\n",
    "        X3=(1-X2)*Applied_Mean\n",
    "        r=(Rate*X2)+X3\n",
    "    \n",
    "        Helper.append(r)\n",
    "        Helper.append(D2)\n",
    "        NewData.append(Helper)\n",
    "\n",
    "        #Δημιουργέι ένα τρίτο data sample με όλα τα χαρακτηριστικά από το αρχικό βάζοντας σαν time slot \n",
    "        #το τρίτο κοντινότερο\n",
    "        #Βάζει σαν ποσοστό παραβατικότητας αυτο που προκύπτει εφαρμόζοντας την γκαουσιανή\n",
    "        #Βάζει την απόσταση 'D3' απο το τρίτο κοντινότερο timeslot\n",
    "        \n",
    "        Mean=Return_Mean(Slot3,Sector,Legal_illegal,Names)\n",
    "        Applied_Mean=Mean*Diff\n",
    "        if Applied_Mean>1:\n",
    "            Applied_Mean=1\n",
    "        \n",
    "        Helper=Scan_List2[i][:11]\n",
    "        Helper.append(Slot3)\n",
    "        X1=((-D3)/0.14583)\n",
    "        X2=np.exp(X1)\n",
    "  \n",
    "        X3=(1-X2)*Applied_Mean\n",
    "        r=(Rate*X2)+X3\n",
    "        \n",
    "        Helper.append(r)\n",
    "        Helper.append(D3)\n",
    "        NewData.append(Helper)\n",
    "\n",
    "    Col=['Slot_id','Key','Date_Sin','Slot_Timeint','Covid','Time_Int','Ilegality_Rate','Holidays','Capacity','Week_Day_Sin','Month_Sin','Real_Time','Real_Rate','Time_Distance']\n",
    "    Legal_illegal = pd.DataFrame (NewData, columns = Col)\n",
    "    \n",
    "    \n",
    "    #Δημιουργεί το τελικό dataset διαγράφοντας τα χαρακτηριστικά που δέν χρειάζονται. \n",
    "    #Αλλάζει θέση σε ένα χαρακτηριστικό ώστε να είναι στην σωστή. \n",
    "    Legal_illegal=Legal_illegal.drop(['Slot_Timeint'], axis=1)\n",
    "    Legal_illegal=Legal_illegal.drop(['Time_Int'], axis=1)\n",
    "    Legal_illegal=Legal_illegal.drop(['Ilegality_Rate'], axis=1)\n",
    "    a=Legal_illegal['Time_Distance']\n",
    "    Legal_illegal=Legal_illegal.drop(['Time_Distance'], axis=1)\n",
    "    Legal_illegal.insert(8, \"Time_Distance\", a, True)\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εφόσον εφόσον χρησιμοποιήσαμε πάνω ένα sample για να δημιουργήσουμε άλλα 2 και δώσαμε τα ίδια χαρακτηριστικά έκτος του ποσοστού παραβατικότητας και του timeslot. Έχουμε δώσει και ίδο 'Key' το key είναι datetime και το χρησιμοποιώ στην συνεχεία για να κάνω merge τις ωριαίες τιμές του καιρού. Εφόσον τα 2 νέα δείγματα αντιπροσωπεύουν άλλη ώρα πρέπει να αλλάξει και το 'Key'. Στην παρακάτω συνάρτηση βρίσκουμε τα σωστά  key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Weather(Legal_illegal):\n",
    "    #Μεταρέπει την ώρα σε κανονική μορφή \n",
    "    Time=Legal_illegal['Real_Time']*timedelta(days=1).total_seconds()\n",
    "    Time=Time/3600\n",
    "    Time=Time.astype(int)\n",
    "    Time=Time.values.tolist()\n",
    "    NewT=[]\n",
    "    #Αν είναι η ώρα 9:00 την μετατρέπει σε 09:00 για να έχει την ιδια μορφή με το key του καιρού\n",
    "    for i in range (0,len(Time)):\n",
    "        Str=str(Time[i])\n",
    "        if Time[i]>=10:\n",
    "            NewT.append(Str)\n",
    "        else:\n",
    "            NewT.append('0'+Str)\n",
    "\n",
    "    #Βάζει στο τέλος της κάθε ώρας το \":00\" για να έχει την ιδια μορφή με το key του καιρού\n",
    "    Time=pd.DataFrame(NewT,columns=[\"Hour\"])\n",
    "    Time= Time[\"Hour\"].map(str)+ ':00'\n",
    "    #Παίρνει και την ημερομηνία\n",
    "    T_List=Legal_illegal.values.tolist()\n",
    "    Date=[]\n",
    "    for i in range (0,len(Legal_illegal)):\n",
    "        D,H=T_List[i][1].split(' ')\n",
    "        Date.append(D)\n",
    "\n",
    "    #Βάζει σαν νεο key την ημερομηνία\n",
    "    Legal_illegal=Legal_illegal.drop(['Key'], axis=1)\n",
    "    Legal_illegal.insert(1, \"Key\", Date, True)\n",
    "    \n",
    "    #Προσθέτει στο νέο key την ώρα\n",
    "    Key_Weather=Legal_illegal['Key'].map(str) + ' ' + Time\n",
    "    Legal_illegal=Legal_illegal.drop(['Key'], axis=1)\n",
    "    \n",
    "    #Πλεον έχω το σωστό key\n",
    "    Legal_illegal.insert(1, \"Key\", Key_Weather, True)\n",
    "    \n",
    "    #Κάνω merge με τα δεδομένα του καιρού\n",
    "    Legal_illegal=pd.merge(Legal_illegal, Final_Weather_Data, on='Key')\n",
    "    \n",
    "    #Legal_illegal=Legal_illegal.drop(['Key'], axis=1)\n",
    "    #print(Legal_illegal.columns)\n",
    "    return Legal_illegal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMeans(Scans_Data2):\n",
    "    Scans_Data2['Key1'] = Scans_Data2['Slot_id'].map(str)+ '+' +Scans_Data2['Key'].map(str)+ '+' +Scans_Data2['Date_Sin'].map(str) + '+' + Scans_Data2['Covid'].map(str)+ '+' + Scans_Data2['Holidays'].map(str)+ '+'+Scans_Data2['Capacity'].map(str)+ '+'+Scans_Data2['Week_Day_Sin'].map(str)+ '+'+Scans_Data2['Month_Sin'].map(str)+ '+'+Scans_Data2['Real_Time'].map(str)+ '+'+Scans_Data2['temp'].map(str)+ '+'+Scans_Data2['humidity'].map(str)\n",
    "    Scans_Data2=Scans_Data2['Key1'],Scans_Data2['Time_Distance'],Scans_Data2['Real_Rate']\n",
    "    Headers=['Key1','Time_Distance','Real_Rate']\n",
    "    Scans_Data2 = pd.concat(Scans_Data2, axis=1, keys=Headers)\n",
    "    \n",
    "    Time_Int = Scans_Data2.groupby([\"Key1\"]).Time_Distance.mean().reset_index()\n",
    "    ILegal_Sum = Scans_Data2.groupby([\"Key1\"]).Real_Rate.mean().reset_index()\n",
    "    Legal_Sum=ILegal_Sum['Key1'],Time_Int['Time_Distance'],ILegal_Sum['Real_Rate']\n",
    "    Headers=['Key1','Time_Distance','Real_Rate']\n",
    "    Legal_illegal = pd.concat(Legal_Sum, axis=1, keys=Headers)\n",
    "    \n",
    "    \n",
    "    Scan_List2=Legal_illegal.values.tolist()\n",
    "    Slot_id=[]\n",
    "    Key=[]\n",
    "    Date_Sin=[]\n",
    "    Covid=[]\n",
    "    Holidays=[]\n",
    "    Capacity=[]\n",
    "    Week_Day_Sin=[]\n",
    "    Month_Sin=[]\n",
    "    Real_Time=[]\n",
    "    temp=[]\n",
    "    humidity=[]\n",
    "    \n",
    "    for i in tqdm(range(0,len(Scan_List2))):\n",
    "        Slot_id_V,Key_V,Date_Sin_V,Covid_V,Holidays_V,Capacity_V,Week_Day_Sin_V,Month_Sin_V,Real_Time_V,temp_V,humidity_V=Scan_List2[i][0].split('+')\n",
    "        Slot_id.append(Slot_id_V)\n",
    "        Key.append(Key_V)\n",
    "        Date_Sin.append(Date_Sin_V)\n",
    "        Covid.append(Covid_V)\n",
    "        Holidays.append(Holidays_V)\n",
    "        Capacity.append(Capacity_V)\n",
    "        Week_Day_Sin.append(Week_Day_Sin_V)\n",
    "        Month_Sin.append(Month_Sin_V)\n",
    "        Real_Time.append(Real_Time_V)\n",
    "        temp.append(temp_V)\n",
    "        humidity.append(humidity_V)\n",
    "    Legal_illegal.insert(1, \"Slot_id\", Slot_id, True)\n",
    "    Legal_illegal.insert(2, \"Key\", Key, True)\n",
    "    Legal_illegal.insert(3, \"Date_Sin\", Date_Sin, True)\n",
    "    Legal_illegal.insert(4, \"Covid\",  Covid, True)\n",
    "    Legal_illegal.insert(5, \"Holidays\", Holidays, True)\n",
    "    Legal_illegal.insert(6, \"Capacity\", Capacity, True)\n",
    "    Legal_illegal.insert(7, \"Week_Day_Sin\", Week_Day_Sin, True)\n",
    "    Legal_illegal.insert(8, \"Month_Sin\", Month_Sin, True)\n",
    "    Legal_illegal.insert(9, \"Real_Time\", Real_Time, True)\n",
    "    Legal_illegal.insert(10, \"temp\", temp, True)\n",
    "    Legal_illegal.insert(11, \"humidity\", humidity, True)\n",
    "    Legal_illegal=Legal_illegal.drop(['Key1'], axis=1)\n",
    "    \n",
    "    Columns2=['Slot_id','Key', 'Date_Sin', 'Covid', 'Holidays', 'Capacity', 'Week_Day_Sin',\n",
    "    'Month_Sin', 'Time_Distance', 'Real_Time', 'Real_Rate', 'temp','humidity']\n",
    "    Legal_illegal=Legal_illegal[Columns2]\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η παρακάτω συνάρτηση κάνει merge με το αρχείο από τις αποστάσεις των τομέων από τα 19 σημεία ενδιαφέροντος και διαγράφει το slot id γιατί δεν το χρησιμοποιούμε στην εκπαίδευση "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Slot_Distances(Legal_illegal):\n",
    "    Legal_illegal['Slot_id'] = Legal_illegal['Slot_id'].astype(float)\n",
    "    Legal_illegal['Slot_id'] = Legal_illegal['Slot_id'].astype(int)\n",
    "    Legal_illegal=pd.merge(Legal_illegal, Distance_Data, on='Slot_id')\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η παρακάτω συνάρτηση ουσιαστικά ενώνει τις τρεις παραπάνω συναρτήσεις και αυτές αποτελούν την διαδικασία του smoothing. Όπου έχοντας σαν είσοδο το data-set που δημιούργησα στο προηγούμενο notebook παίρνω στην έξοδο το smoothed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_Smoothing(Legal_illegal,Names):\n",
    "    Legal_illegal=Smouth(Legal_illegal,Names)\n",
    "    Legal_illegal=Get_Weather(Legal_illegal)\n",
    "    Legal_illegal=GetMeans(Legal_illegal)\n",
    "    Legal_illegal=Get_Slot_Distances(Legal_illegal)\n",
    "    return Legal_illegal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Test(Test): \n",
    "    #Σαν απόσταση βάζει 0, γιατί αφού έχουμε το πραγματικό ποσοστό είναι σαν να θεωρούμε ότι βρίσκεται ακριβώς στο \n",
    "    #κέντρο του time-slot. Εξηγώ τον τύπο αναλυτικότερα στη αναφορά.\n",
    "    Test['Time_Distance']=0\n",
    "    Test=Test.drop(['Time_Int'], axis=1)\n",
    "    a=Test['Slot_Timeint']\n",
    "    b=Test['Ilegality_Rate']\n",
    "    Test=Test.drop(['Slot_Timeint'], axis=1)\n",
    "    Test=Test.drop(['Ilegality_Rate'], axis=1)\n",
    "    Test.insert(9, \"Real_Time\", a, True)\n",
    "    Test.insert(10, \"Real_Rate\", b, True)\n",
    "    Test=pd.merge(Test, Final_Weather_Data, on='Key')\n",
    "    Test=pd.merge(Test, Distance_Data, on='Slot_id')\n",
    "    return Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6214/88870 [00:55<12:20, 111.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m test_data\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(Project_Path\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Data/Test_TimeSeries.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m TestDF\u001b[38;5;241m=\u001b[39mPrepare_Test(test_data) \u001b[38;5;66;03m#No smoothing\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m TrainDF\u001b[38;5;241m=\u001b[39m\u001b[43mApply_Smoothing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNames\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Smoothing\u001b[39;00m\n\u001b[1;32m      7\u001b[0m TrainDF\u001b[38;5;241m=\u001b[39mTrainDF\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Distance\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m TestDF\u001b[38;5;241m=\u001b[39mTestDF\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Distance\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36mApply_Smoothing\u001b[0;34m(Legal_illegal, Names)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mApply_Smoothing\u001b[39m(Legal_illegal,Names):\n\u001b[0;32m----> 2\u001b[0m     Legal_illegal\u001b[38;5;241m=\u001b[39m\u001b[43mSmouth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLegal_illegal\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     Legal_illegal\u001b[38;5;241m=\u001b[39mGet_Weather(Legal_illegal)\n\u001b[1;32m      4\u001b[0m     Legal_illegal\u001b[38;5;241m=\u001b[39mGetMeans(Legal_illegal)\n",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mSmouth\u001b[0;34m(Legal_illegal, Names)\u001b[0m\n\u001b[1;32m     67\u001b[0m NewData\u001b[38;5;241m.\u001b[39mappend(Helper)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#Δημιουργέι ένα τρίτο data sample με όλα τα χαρακτηριστικά από το αρχικό βάζοντας σαν time slot \u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#το τρίτο κοντινότερο\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#Βάζει σαν ποσοστό παραβατικότητας αυτο που προκύπτει εφαρμόζοντας την γκαουσιανή\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#Βάζει την απόσταση 'D3' απο το τρίτο κοντινότερο timeslot\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m Mean\u001b[38;5;241m=\u001b[39m\u001b[43mReturn_Mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSlot3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mSector\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLegal_illegal\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m Applied_Mean\u001b[38;5;241m=\u001b[39mMean\u001b[38;5;241m*\u001b[39mDiff\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Applied_Mean\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mReturn_Mean\u001b[0;34m(Time_Slot, Sector, train_data, Names)\u001b[0m\n\u001b[1;32m      7\u001b[0m     Help\u001b[38;5;241m=\u001b[39mtrain_data[Names]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     Help['Key'] = Help['Slot_id'].map(str)+ '+' +Help['Slot_Timeint'].map(str)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     ILegal_Sum \u001b[38;5;241m=\u001b[39m \u001b[43mHelp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSlot_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSlot_Timeint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIlegality_Rate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     Legal_Sum=ILegal_Sum['Key'],ILegal_Sum['Ilegality_Rate']\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     Help = pd.concat(Legal_Sum, axis=1)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     ILegal_Sum\u001b[38;5;241m=\u001b[39mILegal_Sum\u001b[38;5;241m.\u001b[39mloc[(ILegal_Sum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlot_id\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m(Sector)) \u001b[38;5;241m&\u001b[39m (ILegal_Sum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlot_Timeint\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m\u001b[38;5;28mstr\u001b[39m(Time_Slot))]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1956\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1955\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1956\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1592\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   1588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;66;03m# TypeError -> we may have an exception in trying to aggregate\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;66;03m#  continue and exclude the block\u001b[39;00m\n\u001b[0;32m-> 1592\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ser \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_mgr) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m   1595\u001b[0m     warn_dropping_nuisance_columns_deprecated(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), how)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/internals/base.py:199\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func, ignore_failures)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03mignore_failures : bool, default False\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    Not used; for compatibility with ArrayManager/BlockManager.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[0;32m--> 199\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[1;32m    202\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1578\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1578\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maggregate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1582\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/ops.py:937\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    935\u001b[0m cy_op \u001b[38;5;241m=\u001b[39m WrappedCythonOp(kind\u001b[38;5;241m=\u001b[39mkind, how\u001b[38;5;241m=\u001b[39mhow)\n\u001b[0;32m--> 937\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m\n\u001b[1;32m    938\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[1;32m    940\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    941\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    946\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/_libs/properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/ops.py:834\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 834\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[1;32m    837\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/ops.py:858\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_compressed_codes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]]:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# The first returned ndarray may have any signed integer dtype\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 858\u001b[0m         group_index \u001b[38;5;241m=\u001b[39m get_group_index(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m compress_group_index(group_index, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort)\n\u001b[1;32m    861\u001b[0m     ping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/ops.py:793\u001b[0m, in \u001b[0;36mBaseGrouper.codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [ping\u001b[38;5;241m.\u001b[39mcodes \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/ops.py:793\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:622\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# _codes is set in __init__ for MultiIndex cases\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes\n\u001b[0;32m--> 622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/_libs/properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:690\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         na_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 690\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf2/lib/python3.8/site-packages/pandas/core/algorithms.py:772\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    768\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[1;32m    769\u001b[0m         uniques, codes, na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel, assume_unique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     )\n\u001b[0;32m--> 772\u001b[0m code_is_na \u001b[38;5;241m=\u001b[39m \u001b[43mcodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mna_sentinel\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dropna \u001b[38;5;129;01mand\u001b[39;00m code_is_na\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;66;03m# na_value is set based on the dtype of uniques, and compat set to False is\u001b[39;00m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;66;03m# because we do not want na_value to be 0 for integers\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     na_value \u001b[38;5;241m=\u001b[39m na_value_for_dtype(uniques\u001b[38;5;241m.\u001b[39mdtype, compat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TestDF=Prepare_Test(test_data) #No smoothing\n",
    "TrainDF=Apply_Smoothing(train_data,Names) #Smoothing\n",
    "TrainDF=TrainDF.drop(['Time_Distance'], axis=1)\n",
    "TestDF=TestDF.drop(['Time_Distance'], axis=1)\n",
    "TrainDF.to_csv(Project_Path+ '/Data/Ts_Train_TimeSeries.csv')\n",
    "TestDF.to_csv(Project_Path+ '/Data/Ts_Test_TimeSeries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDF=TrainDF.drop(['Slot_id'], axis=1)\n",
    "TrainDF=TrainDF.drop(['Key'], axis=1)\n",
    "TestDF=TestDF.drop(['Slot_id'], axis=1)\n",
    "TestDF=TestDF.drop(['Key'], axis=1)\n",
    "train_data=TrainDF.drop(['Real_Rate'], axis=1)\n",
    "test_data=TestDF.drop(['Real_Rate'], axis=1)\n",
    "\n",
    "Standar_Scaller = StandardScaler()\n",
    "train_data=Standar_Scaller.fit_transform(train_data)\n",
    "with open(Project_Path + '/Standar_Scaller.pkl', 'wb') as f:\n",
    "    pickle.dump(Standar_Scaller, f,  protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
